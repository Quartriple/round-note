import { useState, useRef, useCallback, useEffect } from 'react';
import { useMicVAD, ReactRealTimeVADOptions } from '@ricky0123/vad-react';

// WebSocket ì„¤ì • ê´€ë ¨ ì „ì—­ ìƒìˆ˜
const WS_URL = process.env.NEXT_PUBLIC_API_URL ? 
    `ws${process.env.NEXT_PUBLIC_API_URL.substring(4)}/api/v1/realtime/ws` : 
    'ws://localhost:8000/api/v1/realtime/ws';

// ì˜¤ë””ì˜¤ ì„¤ì • (Deepgram ìš”êµ¬ì‚¬í•­ì— ë§ì¶¤)
const AUDIO_CONFIG = {
    sampleRate: 16000,
    channel: 1,
    bufferSize: 4096,
};

function float32ToInt16(float32Array: Float32Array): Int16Array {
    let int16Array = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
        // -1.0ì—ì„œ 1.0 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        let s = Math.max(-1, Math.min(1, float32Array[i]));
        // 16ë¹„íŠ¸ ì •ìˆ˜ë¡œ ë³€í™˜
        int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return int16Array;
}

interface RealtimeStreamControls {
    isRecording: boolean;
    isPaused: boolean;
    transcript: string;
    partialText: string;
    translation: string;
    startRecording: () => Promise<void>;
    stopRecording: () => void;
    pauseRecording: () => void;
    resumeRecording: () => void;
    vadLoading: boolean;
}

const useRealtimeStream = (): RealtimeStreamControls => {
    // 1. ìƒíƒœ ì •ì˜
    const [isRecording, setIsRecording] = useState<boolean>(false);
    const [isPaused, setIsPaused] = useState<boolean>(false);
    const [transcript, setTranscript] = useState<string>('');
    const [partialText, setPartialText] = useState<string>('');
    const [translation, setTranslation] = useState<string>('');

    // 2. Mutable ê°ì²´ ì°¸ì¡°
    const wsRef = useRef<WebSocket | null>(null); 
    const isRecordingRef = useRef<boolean>(false); // ìµœì‹  isRecording ìƒíƒœë¥¼ ì¶”ì 
    const isPausedRef = useRef<boolean>(false); // ìµœì‹  isPaused ìƒíƒœë¥¼ ì¶”ì 
    const silenceIntervalRef = useRef<NodeJS.Timeout | null>(null); // ì¹¨ë¬µ ì˜¤ë””ì˜¤ ì „ì†¡ ì¸í„°ë²Œ
    const mediaStreamRef = useRef<MediaStream | null>(null); // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì°¸ì¡°

    // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ì„ ì§ì ‘ ê´€ë¦¬í•˜ì—¬ ì¶”í›„ cleanup ì‹œ íŠ¸ë™ì„ ëª…í™•íˆ ì¢…ë£Œ
    const getOrCreateMediaStream = useCallback(async (): Promise<MediaStream> => {
        if (mediaStreamRef.current) {
            const hasLiveTrack = mediaStreamRef.current.getTracks().some(track => track.readyState === 'live');
            if (hasLiveTrack) {
                return mediaStreamRef.current;
            }
        }

        if (typeof navigator === 'undefined' || !navigator.mediaDevices?.getUserMedia) {
            throw new Error('Audio capture is not supported in this environment');
        }

        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                channelCount: AUDIO_CONFIG.channel,
                sampleRate: AUDIO_CONFIG.sampleRate,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true,
            },
        });

        mediaStreamRef.current = stream;
        return stream;
    }, []);

    const pauseMediaStream = useCallback(async (stream: MediaStream) => {
        stream.getAudioTracks().forEach(track => {
            track.enabled = false;
        });
    }, []);

    const resumeMediaStream = useCallback(async (stream: MediaStream): Promise<MediaStream> => {
        const liveTrackExists = stream.getAudioTracks().some(track => track.readyState === 'live');
        if (!liveTrackExists) {
            mediaStreamRef.current = null;
            return getOrCreateMediaStream();
        }

        stream.getAudioTracks().forEach(track => {
            track.enabled = true;
        });
        mediaStreamRef.current = stream;
        return stream;
    }, [getOrCreateMediaStream]);

    // VAD ì„¤ì • - pause/listening í™•ì¸
    const { loading: vadLoading, start: vadStart, pause: vadPause, userSpeaking, listening } = useMicVAD({
        model: "v5",
        inputSampleRate: AUDIO_CONFIG.sampleRate,
        baseAssetPath: '/',
        onnxWASMBasePath: 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.23.2/dist/',
        getStream: getOrCreateMediaStream,
        pauseStream: pauseMediaStream,
        resumeStream: resumeMediaStream,
        onFrameProcessed: (probs: any, frame: Float32Array) => {
            const isSpeech = probs.isSpeech > 0.6;
            const int16Frame = float32ToInt16(frame);
            
            if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN && int16Frame.buffer.byteLength > 0) {
                // console.log("ì „ì†¡ ë°ì´í„° íƒ€ì…:", int16Frame.buffer instanceof ArrayBuffer);
                wsRef.current.send(int16Frame.buffer);
            }
            
        },
        onSpeechStart: () => {
            console.log("VAD: Speech Started");
        },
        onSpeechEnd: () => {
            console.log("VAD: Speech End");
        },
    } as Partial<ReactRealTimeVADOptions>);

    // isRecording ë³€ê²½ ì‹œ ref ë™ê¸°í™”
    useEffect(() => {
        isRecordingRef.current = isRecording;
    }, [isRecording]);

    // isPaused ë³€ê²½ ì‹œ ref ë™ê¸°í™”
    useEffect(() => {
        isPausedRef.current = isPaused;
    }, [isPaused]);

    // VAD ë¡œë”© ì™„ë£Œ ì‹œ ì¦‰ì‹œ pauseí•˜ì—¬ ë§ˆì´í¬ ìë™ ì‹œì‘ ë°©ì§€
    useEffect(() => {
        if (!vadLoading && vadPause) {
            vadPause();
            console.log("VAD ë¡œë”© ì™„ë£Œ, ìë™ pause ì ìš©ë¨");
        }
    }, [vadLoading, vadPause]);

    // ì¹¨ë¬µ ì˜¤ë””ì˜¤ í”„ë ˆì„ ìƒì„± ë° ì „ì†¡ í•¨ìˆ˜
    const sendSilenceFrame = useCallback(() => {
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            // 100msë¶„ëŸ‰ì˜ ì¹¨ë¬µ ì˜¤ë””ì˜¤ (16000Hz * 0.1s = 1600 samples)
            const silenceFrameSize = Math.floor(AUDIO_CONFIG.sampleRate * 0.1);
            const silenceFrame = new Int16Array(silenceFrameSize).fill(0);
            wsRef.current.send(silenceFrame.buffer);
            // console.log("ì¹¨ë¬µ í”„ë ˆì„ ì „ì†¡");
        }
    }, []);

    // ì¼ì‹œì •ì§€ ì¤‘ ì¹¨ë¬µ ì˜¤ë””ì˜¤ ì „ì†¡ ì¸í„°ë²Œ ê´€ë¦¬
    useEffect(() => {
        if (isPaused && isRecording) {
            // ì¼ì‹œì •ì§€ ìƒíƒœ: 100msë§ˆë‹¤ ì¹¨ë¬µ í”„ë ˆì„ ì „ì†¡
            console.log("ì¹¨ë¬µ ì˜¤ë””ì˜¤ ì „ì†¡ ì‹œì‘ (WebSocket ì—°ê²° ìœ ì§€ìš©)");
            silenceIntervalRef.current = setInterval(() => {
                sendSilenceFrame();
            }, 100); // 100msë§ˆë‹¤
        } else {
            // ì¼ì‹œì •ì§€ í•´ì œ ë˜ëŠ” ë…¹ìŒ ì¤‘ì§€: ì¸í„°ë²Œ ì •ë¦¬
            if (silenceIntervalRef.current) {
                console.log("ì¹¨ë¬µ ì˜¤ë””ì˜¤ ì „ì†¡ ì¤‘ì§€");
                clearInterval(silenceIntervalRef.current);
                silenceIntervalRef.current = null;
            }
        }

        return () => {
            if (silenceIntervalRef.current) {
                clearInterval(silenceIntervalRef.current);
                silenceIntervalRef.current = null;
            }
        };
    }, [isPaused, isRecording, sendSilenceFrame]);

    // ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜
    const cleanupResources = useCallback(() => {
        console.log("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘");
        
        // ì¹¨ë¬µ ì˜¤ë””ì˜¤ ì¸í„°ë²Œ ì •ë¦¬
        if (silenceIntervalRef.current) {
            clearInterval(silenceIntervalRef.current);
            silenceIntervalRef.current = null;
        }
        
        // VAD ì¤‘ì§€ - pause ë©”ì„œë“œ ì‚¬ìš©
        try {
            vadPause();
            console.log("VAD pause í˜¸ì¶œë¨");
        } catch (e) {
            console.error("VAD ì¤‘ì§€ ì˜¤ë¥˜:", e);
        }
        
        // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ refì— ì €ì¥ëœ ê²ƒì´ ìˆë‹¤ë©´ ì¤‘ì§€
        if (mediaStreamRef.current) {
            try {
                mediaStreamRef.current.getTracks().forEach(track => {
                    track.stop();
                    console.log("ì €ì¥ëœ ë§ˆì´í¬ íŠ¸ë™ ì¤‘ì§€:", track.label);
                });
                mediaStreamRef.current = null;
            } catch (e) {
                console.error("ì €ì¥ëœ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ ì˜¤ë¥˜:", e);
            }
        }
        
        // WebSocket ì—°ê²° ë‹«ê¸°
        if (wsRef.current) {
            try {
                const ws = wsRef.current;

                // í•¸ë“¤ëŸ¬ ì œê±°
                ws.onmessage = null;
                ws.onclose = null;
                ws.onerror = null;
                
                if (ws.readyState === WebSocket.OPEN || ws.readyState === WebSocket.CONNECTING) {
                    ws.close();
                }
                wsRef.current = null;
                console.log("WebSocket ì •ë¦¬ë¨");
            } catch (e: unknown) {
                console.error("WebSocket ì •ë¦¬ ì˜¤ë¥˜:", e);
            }
        }
    }, [vadPause]);

    // ë…¹ìŒ ì‹œì‘
    const startRecording = useCallback(async () => {
        if (vadLoading) {
            console.log("VAD ë¡œë”© ì¤‘...");
            return;
        }

        try {
            const wsUrl = WS_URL + "?translate=true";
            console.log("WebSocket ì—°ê²° ì‹œë„:", wsUrl);
            console.log("í™˜ê²½ë³€ìˆ˜ API_URL:", process.env.NEXT_PUBLIC_API_URL);
            
            const ws = new WebSocket(wsUrl);
            wsRef.current = ws;

            // WebSocket ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§
            console.log("WebSocket readyState:", ws.readyState);
            // 0: CONNECTING, 1: OPEN, 2: CLOSING, 3: CLOSED

            // WebSocket ì—°ê²° ëŒ€ê¸°
            await new Promise<void>((resolve, reject) => {
                const timeout = setTimeout(() => {
                    console.error("WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ (5ì´ˆ)");
                    reject(new Error("WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ"));
                }, 5000);

                ws.onopen = (event: Event) => {
                    clearTimeout(timeout);
                    console.log("âœ… WebSocket ì—°ê²° ì„±ê³µ!");
                    console.log("WebSocket readyState:", ws.readyState);
                    resolve();
                };
                
                ws.onerror = (error: Event) => {
                    clearTimeout(timeout);
                    console.error("âŒ WebSocket ì—°ê²° ì˜¤ë¥˜:", error);
                    console.error("WebSocket readyState:", ws.readyState);
                    reject(new Error("WebSocket ì—°ê²° ì‹¤íŒ¨"));
                };
            });

            // WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì„¤ì •
            ws.onmessage = (event: MessageEvent) => {
                console.log("ğŸ“© WebSocket ë©”ì‹œì§€ ìˆ˜ì‹ :", event.data);
                try {
                    const message = JSON.parse(event.data);
                    console.log("íŒŒì‹±ëœ ë©”ì‹œì§€:", message);
                    
                    switch (message.type) {
                        case 'partial_transcript':
                            console.log("ì„ì‹œ ì „ì‚¬:", message.text);
                            setPartialText(message.text);
                            break;
                            
                        case 'final_transcript':
                            console.log("ìµœì¢… ì „ì‚¬:", message.text);
                            setTranscript(prev => {
                                const newText = prev ? prev + '\n' + message.text : message.text;
                                return newText;
                            });
                            setPartialText('');
                            break;
                            
                        case 'translation':
                            console.log("ë²ˆì—­ ê²°ê³¼:", message.translated_text);
                            setTranslation(message.translated_text);
                            break;
                            
                        case 'error':
                            console.error("Server Error:", message.message);
                            setPartialText(`[ERROR]: ${message.message}`);
                            break;
                            
                        default:
                            console.warn("Unknown message type:", message.type);
                    }
                } catch (e: unknown) {
                    console.error("ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:", e);
                    console.error("ì›ë³¸ ë°ì´í„°:", event.data);
                }
            };

            // WebSocket ì¢…ë£Œ í•¸ë“¤ëŸ¬
            ws.onclose = (event: CloseEvent) => {
                console.log("ğŸ”´ WebSocket ì—°ê²° ì¢…ë£Œ");
                console.log("Close code:", event.code);
                console.log("Close reason:", event.reason);
                console.log("Was clean:", event.wasClean);
                console.log("í˜„ì¬ ë…¹ìŒ ìƒíƒœ:", isRecordingRef.current);
                
                // Close code ì„¤ëª…
                const closeCodeMessages = {
                    1000: "ì •ìƒ ì¢…ë£Œ",
                    1001: "ì„œë²„ ì¢…ë£Œ",
                    1006: "ë¹„ì •ìƒ ì¢…ë£Œ (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë˜ëŠ” ì„œë²„ ë¬¸ì œ)",
                    1011: "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜",
                    1012: "ì„œë²„ ì¬ì‹œì‘",
                } as const;
                const closeReason = closeCodeMessages[event.code as keyof typeof closeCodeMessages] || "ì•Œ ìˆ˜ ì—†ìŒ";
                
                if (isRecordingRef.current) {
                    setIsRecording(false);
                    setTranscript(prev => prev + `\n[ì„œë²„ ì—°ê²° ì¢…ë£Œ - Code: ${event.code}, ${closeReason}]`);
                }
            };

            // WebSocket ì—ëŸ¬ í•¸ë“¤ëŸ¬ ì¶”ê°€
            ws.onerror = (error: Event) => {
                console.error("WebSocket ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:", error);
            };

            // VAD ì‹œì‘ - start ë©”ì„œë“œ ì‚¬ìš© (VADê°€ ë‚´ë¶€ì ìœ¼ë¡œ ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬)
            if (typeof vadStart === 'function') {
                vadStart();
                console.log("VAD ì‹œì‘ë¨");
            }

            setIsRecording(true);
            setTranscript('ğŸ™ï¸ ì‹¤ì‹œê°„ ì „ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.');

        } catch (e: unknown) {
            console.error("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:", e);
            cleanupResources();
            setIsRecording(false);
            setTranscript('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ' + (e instanceof Error ? e.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"));
        }
    }, [vadLoading, vadStart, cleanupResources]);

    // ë…¹ìŒ ì¤‘ì§€
    const stopRecording = useCallback(() => {
        if (!isRecording) {
            console.log("ì´ë¯¸ ë…¹ìŒì´ ì¤‘ì§€ë¨");
            return;
        }
        
        console.log("ë…¹ìŒ ì¤‘ì§€ ì‹œì‘");
        cleanupResources();

        setIsRecording(false);
        setIsPaused(false); // ì¼ì‹œì •ì§€ ìƒíƒœë„ ë¦¬ì…‹
        setPartialText('');
        setTranscript(prev => prev + '\n[ë…¹ìŒ ì¢…ë£Œ]');
        console.log("ë…¹ìŒ ì¤‘ì§€ ì™„ë£Œ");

    }, [isRecording, cleanupResources]);

    // ë…¹ìŒ ì¼ì‹œì •ì§€ (WebSocketì€ ìœ ì§€, VADë§Œ pause)
    const pauseRecording = useCallback(() => {
        if (!isRecording || isPaused) {
            console.log("ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ì´ë¯¸ ì¼ì‹œì •ì§€ë¨");
            return;
        }
        
        console.log("ë…¹ìŒ ì¼ì‹œì •ì§€");
        try {
            // ë°±ì—”ë“œì— ì¼ì‹œì •ì§€ ìƒíƒœ ì•Œë¦¼
            if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
                wsRef.current.send(JSON.stringify({ command: "SET_PAUSED", value: true }));
                console.log("ì¼ì‹œì •ì§€ ì œì–´ ë©”ì‹œì§€ ì „ì†¡");
            }
            
            vadPause();
            setIsPaused(true);
            console.log("VAD ì¼ì‹œì •ì§€ ì™„ë£Œ");
        } catch (e) {
            console.error("VAD ì¼ì‹œì •ì§€ ì˜¤ë¥˜:", e);
        }
    }, [isRecording, isPaused, vadPause]);

    // ë…¹ìŒ ì¬ê°œ (VADë§Œ restart)
    const resumeRecording = useCallback(() => {
        if (!isRecording || !isPaused) {
            console.log("ë…¹ìŒ ì¤‘ì´ ì•„ë‹ˆê±°ë‚˜ ì¼ì‹œì •ì§€ ìƒíƒœê°€ ì•„ë‹˜");
            return;
        }
        
        console.log("ë…¹ìŒ ì¬ê°œ");
        try {
            // ë°±ì—”ë“œì— ì¬ê°œ ìƒíƒœ ì•Œë¦¼
            if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
                wsRef.current.send(JSON.stringify({ command: "SET_PAUSED", value: false }));
                console.log("ì¬ê°œ ì œì–´ ë©”ì‹œì§€ ì „ì†¡");
            }
            
            vadStart();
            setIsPaused(false);
            console.log("VAD ì¬ê°œ ì™„ë£Œ");
        } catch (e) {
            console.error("VAD ì¬ê°œ ì˜¤ë¥˜:", e);
        }
    }, [isRecording, isPaused, vadStart]);

    // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
    useEffect(() => {
        return () => {
            console.log("ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘");
            
            // ì¹¨ë¬µ ì¸í„°ë²Œ ì •ë¦¬
            if (silenceIntervalRef.current) {
                clearInterval(silenceIntervalRef.current);
                silenceIntervalRef.current = null;
            }
            
            // VAD ê°•ì œ ì¤‘ì§€
            try {
                if (vadPause) {
                    vadPause();
                    console.log("ì–¸ë§ˆìš´íŠ¸ ì‹œ VAD pause í˜¸ì¶œ");
                }
            } catch (e) {
                console.error("ì–¸ë§ˆìš´íŠ¸ ì‹œ VAD pause ì˜¤ë¥˜:", e);
            }
            
            // ë§ˆì´í¬ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
            if (mediaStreamRef.current) {
                mediaStreamRef.current.getTracks().forEach(track => {
                    track.stop();
                    console.log("ì–¸ë§ˆìš´íŠ¸ ì‹œ ë§ˆì´í¬ íŠ¸ë™ ì¤‘ì§€:", track.label);
                });
                mediaStreamRef.current = null;
            }
            
            // WebSocket ì •ë¦¬
            if (wsRef.current) {
                const ws = wsRef.current;
                ws.onmessage = null;
                ws.onclose = null;
                ws.onerror = null;
                if (ws.readyState === WebSocket.OPEN) {
                    ws.close();
                }
                wsRef.current = null;
            }
            
            console.log("ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ - ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
        };
    }, [vadPause]);

    return {
        isRecording: isRecording || vadLoading,
        isPaused,
        transcript,
        partialText,
        translation,
        startRecording,
        stopRecording,
        pauseRecording,
        resumeRecording,
        vadLoading: vadLoading,
    };
};

export default useRealtimeStream;